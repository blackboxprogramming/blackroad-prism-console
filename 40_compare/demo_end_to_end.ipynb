{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# End-to-end metric sanity check\n",
        "\n",
        "This quick notebook fabricates a few tiny synthetic simulation outputs and runs the comparison utilities to make sure everything is wired together."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import importlib\n",
        "import sys\n",
        "from pathlib import Path\n",
        "import tempfile\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# Make sure the repository root is on the import path so we can load\n",
        "# ``40_compare.io_utils`` even when executing the notebook in place.\n",
        "NOTEBOOK_DIR = Path.cwd()\n",
        "REPO_ROOT = NOTEBOOK_DIR if (NOTEBOOK_DIR / \"40_compare\").is_dir() else NOTEBOOK_DIR.parent\n",
        "if str(REPO_ROOT) not in sys.path:\n",
        "    sys.path.append(str(REPO_ROOT))\n",
        "\n",
        "io_utils = importlib.import_module(\"40_compare.io_utils\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def write_ascii_ply(points: np.ndarray, path: Path) -> None:\n",
        "    \"\"\"Write a minimal ASCII PLY point cloud to ``path``.\"\"\"\n",
        "\n",
        "    header = (\"ply\\n\"\n",
        "              \"format ascii 1.0\\n\"\n",
        "              \"comment generated by universal sim starter\\n\"\n",
        "              f\"element vertex {len(points)}\\n\"\n",
        "              \"property float x\\n\"\n",
        "              \"property float y\\n\"\n",
        "              \"property float z\\n\"\n",
        "              \"end_header\\n\")\n",
        "\n",
        "    with path.open(\"w\", encoding=\"utf-8\") as fh:\n",
        "        fh.write(header)\n",
        "        for x, y, z in points:\n",
        "            fh.write(f\"{x:.6f} {y:.6f} {z:.6f}\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "rng = np.random.default_rng(8)\n",
        "demo_dir = Path(tempfile.mkdtemp(prefix=\"sim_demo_\"))\n",
        "\n",
        "# -----------------------------------------------------------------\n",
        "# Synthetic point clouds (noisy spheres)\n",
        "# -----------------------------------------------------------------\n",
        "n_points = 512\n",
        "phi = rng.uniform(0, 2 * np.pi, size=n_points)\n",
        "costheta = rng.uniform(-1.0, 1.0, size=n_points)\n",
        "theta = np.arccos(costheta)\n",
        "r = np.ones(n_points)\n",
        "\n",
        "base_cloud = np.stack(\n",
        "    [\n",
        "        r * np.sin(theta) * np.cos(phi),\n",
        "        r * np.sin(theta) * np.sin(phi),\n",
        "        r * np.cos(theta),\n",
        "    ],\n",
        "    axis=1,\n",
        ")\n",
        "\n",
        "cloud_a = base_cloud\n",
        "cloud_b = base_cloud * (1.0 + 0.02 * rng.standard_normal(base_cloud.shape))\n",
        "cloud_b[:, 0] += 0.05  # slight translation in X.\n",
        "\n",
        "write_ascii_ply(cloud_a, demo_dir / \"cloud_a.ply\")\n",
        "write_ascii_ply(cloud_b, demo_dir / \"cloud_b.ply\")\n",
        "\n",
        "# -----------------------------------------------------------------\n",
        "# Synthetic scalar fields (Gaussian blobs on a 32^3 grid)\n",
        "# -----------------------------------------------------------------\n",
        "grid = np.linspace(-1.0, 1.0, 32)\n",
        "X, Y, Z = np.meshgrid(grid, grid, grid, indexing=\"ij\")\n",
        "\n",
        "field_a = np.exp(-4.0 * (X**2 + Y**2 + Z**2))\n",
        "field_b = np.exp(-4.0 * ((X - 0.1) ** 2 + (Y + 0.05) ** 2 + Z**2))\n",
        "\n",
        "np.savez_compressed(demo_dir / \"field_a.npz\", scalar_field=field_a.astype(np.float32))\n",
        "np.save(demo_dir / \"field_b.npy\", field_b.astype(np.float32))\n",
        "\n",
        "print(f\"Demo assets stored in: {demo_dir}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def chamfer_distance(a: np.ndarray, b: np.ndarray) -> float:\n",
        "    \"\"\"Compute a simple two-sided Chamfer distance.\"\"\"\n",
        "\n",
        "    diff = a[:, None, :] - b[None, :, :]\n",
        "    dist = np.linalg.norm(diff, axis=2)\n",
        "    return float(dist.min(axis=1).mean() + dist.min(axis=0).mean())\n",
        "\n",
        "\n",
        "def rms_difference(a: np.ndarray, b: np.ndarray) -> float:\n",
        "    return float(np.sqrt(np.mean((a - b) ** 2)))\n",
        "\n",
        "\n",
        "def volumetric_iou(a: np.ndarray, b: np.ndarray, threshold: float = 0.5) -> float:\n",
        "    mask_a = a >= threshold\n",
        "    mask_b = b >= threshold\n",
        "    intersection = np.logical_and(mask_a, mask_b).sum()\n",
        "    union = np.logical_or(mask_a, mask_b).sum()\n",
        "    return float(intersection / union)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cloud_a_loaded = io_utils.load_point_cloud_ply(demo_dir / \"cloud_a.ply\")\n",
        "cloud_b_loaded = io_utils.load_point_cloud_ply(demo_dir / \"cloud_b.ply\")\n",
        "\n",
        "field_a_loaded = io_utils.load_npz_scalar_field(demo_dir / \"field_a.npz\")\n",
        "field_b_loaded = io_utils.load_npy(demo_dir / \"field_b.npy\")\n",
        "\n",
        "metrics = {\n",
        "    \"chamfer_distance\": chamfer_distance(cloud_a_loaded, cloud_b_loaded),\n",
        "    \"scalar_field_rms\": rms_difference(field_a_loaded, field_b_loaded),\n",
        "    \"volumetric_iou\": volumetric_iou(field_a_loaded, field_b_loaded),\n",
        "}\n",
        "metrics\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End-to-end metrics sanity check\n",
    "Run the pipeline steps (`make dummy`, `make mpm`, `make pysph`) before executing the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sim_pipeline.report import collect_metrics, evaluate_thresholds\n",
    "metrics = collect_metrics()\n",
    "checks = evaluate_thresholds(metrics)\n",
    "metrics, checks, all(checks.values())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
