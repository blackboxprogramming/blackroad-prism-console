# /opt/blackroad/models/docker-compose.yml
version: "3.9"
services:
  ollama:
    image: ollama/ollama:latest
    volumes:
      - models:/root/.ollama
      - ./models.json:/models/models.json:ro
      - ./load_models.sh:/models/load_models.sh:ro
    command: /models/load_models.sh && ollama serve
    ports:
      - "11434:11434"
  openai:
    image: ghcr.io/go-skynet/ollama-proxy:latest
    environment:
      - OLLAMA_BASE_URL=http://ollama:11434
    ports:
      - "8000:8000"
    depends_on:
      - ollama
volumes:
  models:
